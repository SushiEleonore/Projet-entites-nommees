{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/eleonore/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/eleonore/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "BELEODAQ.tab, 1/101\n",
      "MULTAQ.tab, 2/101\n",
      "DALVANCE.tab, 3/101\n",
      "NORTHERA.tab, 4/101\n",
      "IMBRUVICA.tab, 5/101\n",
      "DOTAREM.tab, 6/101\n",
      "ERWINAZE.tab, 7/101\n",
      "ULORIC.tab, 8/101\n",
      "JARDIANCE.tab, 9/101\n",
      "EOVIST.tab, 10/101\n",
      "ARCAPTA.tab, 11/101\n",
      "TAFINLAR.tab, 12/101\n",
      "DUAVEE.tab, 13/101\n",
      "VORAXAZE.tab, 14/101\n",
      "FULYZAQ.tab, 15/101\n",
      "NATAZIA.tab, 16/101\n",
      "FARXIGA.tab, 17/101\n",
      "ADCETRIS.tab, 18/101\n",
      "OTEZLA.tab, 19/101\n",
      "ZERBAXA.tab, 20/101\n",
      "BENLYSTA.tab, 21/101\n",
      "COMETRIQ.tab, 22/101\n",
      "HALAVEN.tab, 23/101\n",
      "DIFICID.tab, 24/101\n",
      "SAPHRIS.tab, 25/101\n",
      "JEVTANA.tab, 26/101\n",
      "KYPROLIS.tab, 27/101\n",
      "TANZEUM.tab, 28/101\n",
      "STRIBILD.tab, 29/101\n",
      "ZYDELIG.tab, 30/101\n",
      "ZYTIGA.tab, 31/101\n",
      "NULOJIX.tab, 32/101\n",
      "BOSULIF.tab, 33/101\n",
      "TIVICAY.tab, 34/101\n",
      "TOVIAZ.tab, 35/101\n",
      "JUBLIA.tab, 36/101\n",
      "BESIVANCE.tab, 37/101\n",
      "CERDELGA.tab, 38/101\n",
      "EDARBI.tab, 39/101\n",
      "GILOTRIF.tab, 40/101\n",
      "ZYKADIA.tab, 41/101\n",
      "TEFLARO.tab, 42/101\n",
      "COARTEM.tab, 43/101\n",
      "HORIZANT.tab, 44/101\n",
      "PROMACTA.tab, 45/101\n",
      "POTIGA.tab, 46/101\n",
      "XALKORI.tab, 47/101\n",
      "ULESFIA.tab, 48/101\n",
      "TECFIDERA.tab, 49/101\n",
      "PRISTIQ.tab, 50/101\n",
      "QUTENZA.tab, 51/101\n",
      "XTANDI.tab, 52/101\n",
      "DATSCAN.tab, 53/101\n",
      "AMYVID.tab, 54/101\n",
      "ONFI.tab, 55/101\n",
      "GILENYA.tab, 56/101\n",
      "INLYTA.tab, 57/101\n",
      "VIZAMYL.tab, 58/101\n",
      "FIRAZYR.tab, 59/101\n",
      "FERRIPROX.tab, 60/101\n",
      "STENDRA.tab, 61/101\n",
      "INVOKANA.tab, 62/101\n",
      "ADREVIEW.tab, 63/101\n",
      "PROLIA.tab, 64/101\n",
      "YERVOY.tab, 65/101\n",
      "ENTEREG.tab, 66/101\n",
      "KALBITOR.tab, 67/101\n",
      "ILARIS.tab, 68/101\n",
      "NESINA.tab, 69/101\n",
      "APTIOM.tab, 70/101\n",
      "BEPREVE.tab, 71/101\n",
      "TRULICITY.tab, 72/101\n",
      "XIAFLEX.tab, 73/101\n",
      "PRADAXA.tab, 74/101\n",
      "XEOMIN.tab, 75/101\n",
      "BREO.tab, 76/101\n",
      "LUMIZYME.tab, 77/101\n",
      "VICTRELIS.tab, 78/101\n",
      "CHOLINE.tab, 79/101\n",
      "DUREZOL.tab, 80/101\n",
      "TUDORZA.tab, 81/101\n",
      "EYLEA.tab, 82/101\n",
      "FANAPT.tab, 83/101\n",
      "NEURACEQ.tab, 84/101\n",
      "AFINITOR.tab, 85/101\n",
      "VIMIZIM.tab, 86/101\n",
      "CLEVIPREX.tab, 87/101\n",
      "GADAVIST.tab, 88/101\n",
      "GRANIX.tab, 89/101\n",
      "DYSPORT.tab, 90/101\n",
      "PICATO.tab, 91/101\n",
      "AMPYRA.tab, 92/101\n",
      "INTELENCE.tab, 93/101\n",
      "SIMPONI.tab, 94/101\n",
      "BLINCYTO.tab, 95/101\n",
      "CARBAGLU.tab, 96/101\n",
      "SIRTURO.tab, 97/101\n",
      "KALYDECO.tab, 98/101\n",
      "ELIQUIS.tab, 99/101\n",
      "CIMZIA.tab, 100/101\n",
      "TREANDA.tab, 101/101\n",
      "nb de mots total : 26787\n",
      "nb de mots dans meddra : 2457\n",
      "nb de mots dans meddra après normalisation de la casse : 9352\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import random\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "path = \"data/\"\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "#Pour faire des statistiques sur les catégories morpho-syntaxiques\n",
    "morpho_stat = dict()\n",
    "\n",
    "tot_w = 0 #Nombre de mots total\n",
    "tot_w_med = 0 #Nombre de mots pouvant etre trouvés dans meddra tels quels\n",
    "tot_w_med_casse = 0 #Nombre de mots pouvant etre trouvés dans meddra après normalisation de la casse\n",
    "\n",
    "#Format : mot normal, tag nltk, mot casse normalisée, mot lemmatisé, mot racinisé, si le mot est dans meddra, classe\n",
    "\n",
    "#TODO se servir de https://www.nlm.nih.gov/research/umls/\n",
    "#Enlever les 3 premieres lignes.\n",
    "\n",
    "#Thesaurus meddra\n",
    "file = open(\"umls-mrconso-mdr-llt-pt.tab\", \"r\")\n",
    "meddra = file.read()\n",
    "lines = meddra.split(\"\\n\")\n",
    "medterms = []\n",
    "medterms_low = []\n",
    "for line in lines :\n",
    "    words =line.split(\"\\t\")\n",
    "    medterms.append(words[len(words)-1])\n",
    "    medterms_low.append(words[len(words)-1].lower())\n",
    "#print(medterms_low)\n",
    "\n",
    "def search_meddra(mot, stat):\n",
    "    global tot_w_med\n",
    "    global tot_w_med_casse\n",
    "    if mot in medterms:\n",
    "        tot_w_med +=1*stat\n",
    "    if mot.lower() in medterms_low:\n",
    "        tot_w_med_casse +=1*stat\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "\n",
    "def process_file(txt, name):\n",
    "    global test\n",
    "    global train\n",
    "    global dev\n",
    "    global tot_w\n",
    "    lines = txt.split(\"\\n\")\n",
    "    newtxt = \"\"\n",
    "    curr_sen = [] #La phrase courante pour le pos tagging\n",
    "    curr_processed_sen= []\n",
    "    for line in lines :\n",
    "        words = line.split(\"\\t\")\n",
    "        if len(words)==3:\n",
    "            in_meddra = \"N\"\n",
    "            \n",
    "            #Pour les statistiques\n",
    "            if(words[2] != \"O\"):#Si c'est un mot qui désigne un effet secondaire\n",
    "                tot_w +=1\n",
    "                if search_meddra(words[0],1):\n",
    "                    in_meddra = \"Y\"\n",
    "            #En pratique, on teste tous les mots puisqu'on est pas censés connaître leur classe\n",
    "            else:\n",
    "                if (search_meddra(words[0],0)):\n",
    "                    in_meddra = \"Y\"\n",
    "            w = words[0].lower()\n",
    "            curr_sen.append(words[0])\n",
    "            lem = lemmatizer.lemmatize(w)\n",
    "            stem = stemmer.stem(w)\n",
    "            curr_processed_sen.append(w + \"\\t\"+lem + \"\\t\" + stem +\"\\t\"+  in_meddra + \"\\t\" +words[2])\n",
    "        elif len(words)==1:\n",
    "            tagged = nltk.pos_tag(curr_sen)\n",
    "            processed = \"\"\n",
    "            for i in range(len(curr_processed_sen)):\n",
    "                processed = processed +curr_sen[i] + \"\\t\" + tagged[i][1]+ \"\\t\" + curr_processed_sen[i]+ \"\\n\"\n",
    "            curr_processed_sen = []\n",
    "            curr_sen =[]\n",
    "            newtxt = newtxt + processed + \"\\n\"\n",
    "    file = open(\"processednew/\" + name, \"w\") #trouver nom fichier\n",
    "    file.write(newtxt)\n",
    "    file.close()\n",
    "cpt =1\n",
    "for file in os.listdir(path):\n",
    "    file = open(path + file, \"r\") \n",
    "    n = file.name.split(\"/\")[1]\n",
    "    print(n + \", \" + str(cpt)+\"/101\")\n",
    "    cpt+=1\n",
    "    txt = file.read()\n",
    "    process_file(txt, n)\n",
    "    #break\n",
    "\n",
    "print(\"nb de mots total : \" +str(tot_w))\n",
    "print(\"nb de mots dans meddra : \" + str(tot_w_med))\n",
    "print(\"nb de mots dans meddra après normalisation de la casse : \" + str(tot_w_med_casse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
